<?xml version="1.0" encoding="utf-8"?>
<!--Please note: Paths and extensions defined herein are considered as case-sensitive in OptimizeRasters.py -->
<OptimizeRasters>
  <Defaults>
    <!-- Acceptable modes are [mrf, mrf_jpeg, tif, tif_lzw, tif_jpeg, cachingmrf, clonemrf, splitmrf] -->
    <Mode>mrf</Mode>
    <!-- File extensions considered as (Rasters). These files will not be copied from the input path -->
    <RasterFormatFilter>tif,TIF, mrf</RasterFormatFilter>
    <!-- File extensions to ignore completely while copying files/data from the input path -->
    <ExcludeFilter>tmp, ovr, rrd, idx, lrc, mrf_cache, pjp, ppng, pft, pzp</ExcludeFilter>
    <!-- Compression to use on output (Rasters) -->
    <Compression>lerc</Compression>
    <Interleave></Interleave>
    <!-- Compression quality to apply for JPEG compression. (Def: 85) -->
    <Quality>85</Quality>
    <!-- LERC precision to apply for LERC compression -->
    <LERCPrecision></LERCPrecision>
    <!-- Build pyramids? Acceptable values are [true, yes, t, 1, y, false, no, f, 0, n, only, external] -->
    <BuildPyramids>true</BuildPyramids>
    <!-- Pyramid levels to create (Def:  2) -->
    <PyramidFactor>2 4 8 16 32 64</PyramidFactor>
    <!-- Pyramid sampling [nearest,average,gauss,cubic,cubicspline,lanczos,average_mp,average_magphase,mode] (Def: average) -->
    <PyramidSampling>average</PyramidSampling>
    <!--  Pyramid compression [jpeg, lzw, deflate] (Def: jpeg) -->
    <PyramidCompression>JPEG</PyramidCompression>
    <!-- No data value. If undefined/empty value  -a_nodata will not be applied. (Def: undefined) -->
    <NoDataValue></NoDataValue>
    <!-- Output tile size -->
    <BlockSize>512</BlockSize>
    <!-- This needs to specified when generating caching or clone MRF, the value should be based on the input raster pyramid factor default is 2  -->
    <Scale></Scale>
    <!-- ‘True’ to keep input raster extensions else outputs will be renamed to ‘mrf’. Acceptable values are [true, yes, t, 1, y, false, no, f, 0, n] -->
    <KeepExtension>True</KeepExtension>
    <!-- Simultaneous threads to use for parallel processing /instances of gdal_translate/gdal_addo/e.t.c (Def: 10) -->
    <Threads>10</Threads>
    <!-- Path where the logs will be stored -->
    <LogPath>.</LogPath>
    <!-- 'True' will scan for (Rasters) in sub-directories. Acceptable values are [true, yes, t, 1, y, false, no, f, 0, n] -->
    <IncludeSubdirectories>True</IncludeSubdirectories>
    <Out_S3_AWS_ProfileName>default</Out_S3_AWS_ProfileName>
    <Out_S3_ID>Out_S3_ID</Out_S3_ID>
    <Out_S3_Secret>Out_S3_secret_key</Out_S3_Secret>
    <Out_S3_Bucket>Out_BucketName</Out_S3_Bucket>
    <!-- Set canned ACL to apply to uploaded files. Acceptable values are [private, public-read, public-read-write, authenticated-read, bucket-owner-read,bucket-owner-full-control]-->
    <Out_S3_ACL></Out_S3_ACL>
    <!-- Starting output folder location to store converted data on S3-->
    <Out_S3_ParentFolder>Out_S3Parent_folder</Out_S3_ParentFolder>
    <!-- If ‘true’ generated output files with any extra files copied from input will be uploaded to S3. Acceptable values are [true, yes, t, 1, y, false, no, f, 0, n] -->
    <Out_S3_Upload>F</Out_S3_Upload>
    <!-- If ‘true’ generated output will be deleted once uploaded to S3. Acceptable values are [true, yes, t, 1, y, false, no, f, 0, n] -->
    <Out_S3_DeleteAfterUpload>True</Out_S3_DeleteAfterUpload>
    <In_S3_AWS_ProfileName>default</In_S3_AWS_ProfileName>
    <In_S3_ID>In_S3_ID</In_S3_ID>
    <In_S3_Secret>In_S3_Secret</In_S3_Secret>
    <In_S3_Bucket>In_BucketName</In_S3_Bucket>
    <!-- Starting input folder to scan for (Rasters) and to copy any other files that do not end with extensions in <ExcludeFilter> -->
    <In_S3_ParentFolder>sampletest/02042014</In_S3_ParentFolder>
  </Defaults>
</OptimizeRasters>
